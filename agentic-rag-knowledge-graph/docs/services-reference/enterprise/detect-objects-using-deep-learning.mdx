---
title: "Detect Objects Using Deep Learning"
description: "API reference for the Detect Objects Using Deep Learning service available in ArcGIS Enterprise."
slug: "detect-objects-using-deep-learning"
url: "/detect-objects-using-deep-learning"
guid: "GUID-EAD905D4-E9F4-4FD7-AAD3-09D9F35FFD30"
migratedTopicMetadata:
  FTITLE: "Detect Objects Using Deep Learning"
  FDESCRIPTION: ""
  FCHANGES: "Removing related resources re: https://devtopia.esri.com/WebGIS/arcgis-rest-api-documentation/issues/191"
  FISHRELEASELABEL: ""
  FESRISOFTWARERELEASE: ""
  FESRITAGCLOUD: ""
  FESRIRECREATIONPROCEDURE: ""
  FESRIPRODUCTLIFECYCLE: "10.9 - *"
  CREATED-ON: "12/09/2022 16:06:08"
  FAUTHOR: "tohara"
  FSTATUS: "Released"
  MODIFIED-ON: "20/09/2022 11:06:21"
  VERSION: "6"
  FRESOLUTION: ""
  DOC-LANGUAGE: "en"
  FISHREVCOUNTER: "2"
  ED: "GUID-A0D024A5-B8D6-4D42-95F8-BC0B7C299D86"
  FUSERGROUP: ""
  READ-ACCESS: ""
restInfoMetadata:
  apiPath: /DetectObjectsUsingDeepLearning
  urlSegments:
    - name: <rasteranalysistools-url>
      url: /raster-analysis-tasks-overview
    - name: /DetectObjectsUsingDeepLearning
  methods: []
  sslOnly: 'no'
  versionIntroduced: '10.7'
---

import GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_LI_2DDA48A24C404781BB03BF05B81B3C19 from "./snippets/GUID-92B97D46-70DD-4B77-80C3-E6A319680CD9/_LI_2DDA48A24C404781BB03BF05B81B3C19";
import GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_LI_1744B5CA044F44D8ABF2E27EF9BC9A27 from "./snippets/GUID-92B97D46-70DD-4B77-80C3-E6A319680CD9/_LI_1744B5CA044F44D8ABF2E27EF9BC9A27";
import GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_LI_30623A2523584FB586A882C09EA092E6 from "./snippets/GUID-92B97D46-70DD-4B77-80C3-E6A319680CD9/_LI_30623A2523584FB586A882C09EA092E6";
import GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_LI_CE9516B4F2CC486AB1D7309DCF46BB60 from "./snippets/GUID-92B97D46-70DD-4B77-80C3-E6A319680CD9/_LI_CE9516B4F2CC486AB1D7309DCF46BB60";
import GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_LI_E6010ACCD39749768E03E99ED0668169 from "./snippets/GUID-92B97D46-70DD-4B77-80C3-E6A319680CD9/_LI_E6010ACCD39749768E03E99ED0668169";
import GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_LI_6DD48DC1AA3045459CB9C0154F7E1928 from "./snippets/GUID-92B97D46-70DD-4B77-80C3-E6A319680CD9/_LI_6DD48DC1AA3045459CB9C0154F7E1928";
import GUID_187EFF3C_6544_4421_8D1E_9DFCF76354CD_GUID_56FBFBA3_C66E_404D_8D62_38D68537B266 from "./snippets/GUID-187EFF3C-6544-4421-8D1E-9DFCF76354CD/_GUID-56FBFBA3-C66E-404D-8D62-38D68537B266";
import GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_GUID_1702083F_151C_4A0C_AF36_0D0DD9E2563A from "./snippets/GUID-92B97D46-70DD-4B77-80C3-E6A319680CD9/_GUID-1702083F-151C-4A0C-AF36-0D0DD9E2563A";
import GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_GUID_4B398B66_01FD_40FB_9AEE_30371F0A8CD8 from "./snippets/GUID-92B97D46-70DD-4B77-80C3-E6A319680CD9/_GUID-4B398B66-01FD-40FB-9AEE-30371F0A8CD8";
import GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_GUID_ED11CCC7_40D3_4ADD_A679_A3F6964834ED from "./snippets/GUID-92B97D46-70DD-4B77-80C3-E6A319680CD9/_GUID-ED11CCC7-40D3-4ADD-A679-A3F6964834ED";
import GUID_187EFF3C_6544_4421_8D1E_9DFCF76354CD_GUID_D4B95D4E_8EB2_4216_A791_F294FC055A0B from "./snippets/GUID-187EFF3C-6544-4421-8D1E-9DFCF76354CD/_GUID-D4B95D4E-8EB2-4216-A791-F294FC055A0B";
import GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_LI_E5BF6567427444E8B74C6B8212C56B99 from "./snippets/GUID-92B97D46-70DD-4B77-80C3-E6A319680CD9/_LI_E5BF6567427444E8B74C6B8212C56B99";

## Description

![Detect Objects Using Deep Learning diagram](./images/GUID-EE76A33E-0B8F-48EE-94F8-782FAD241D72-web.png)

The `DetectObjectsUsingDeepLearning`  operation can be used to detect objects from the imagery data using the designated deep learning model and generate a feature service for the detected objects.

##  Request parameters

<StyledTable headers={"Parameter,Details"}>
<StyledTableRow>
<StyledTableCell cellStyle="markdown">

`inputRaster` 

(Required)

</StyledTableCell>
<StyledTableCell cellStyle="markdown">

The input image used to detect objects. This can be specified as the portal item ID, image service URL, cloud raster dataset, shared raster dataset, a feature service with image attachments, or a raster dataset or image collection in the data store. At least one type of input must be provided in the JSON object. If multiple inputs are provided, the `itemId`  takes priority.

Syntax: A JSON object describes the input raster.

Example:

```javascript
//Portal Item ID
inputRaster={"itemId": <portal item id>}

//Image Service URL
inputRaster={"url": <image service url>}

//Feature Service URL
inputRaster={"url": <feature service url>}

//Cloud Raster URI or Shared Data Path
inputRaster={"uri": <cloud raster uri or shared data path>}

//Service Properties
inputRaster={"serviceProperties":{"name":"testrasteranalysis","serviceUrl":"https://<server name>/server/rest/services/Hosted/testrasteranalysis/ImageServer"},"itemProperties":{"itemId":"8cfbd3ec25584d0d8f4ed23b8ff7c43b", "folderId":"sdfwerfbd3ec25584d0d8f4"}}

//Data store URI 
inputRaster={"uri":"/rasterStores/rasterstorename/A/B/C"}
or
inputRaster={"uri":"/fileShares/filesharedatastorename/A/B/C"}
or
inputRaster={"uri":"/cloudStores/cloudstorename/A/B/C"}
```

 

</StyledTableCell>
</StyledTableRow>
<StyledTableRow>
<StyledTableCell cellStyle="markdown">

`outputObjects` 

(Required)

</StyledTableCell>
<StyledTableCell cellStyle="markdown">

The output hosted feature service properties. If there is an existing hosted feature service, you can provide the portal item ID or service URL and the output path of the generated feature class will be used to update the existing service definition. The service tool can also generate a new hosted feature service with the service properties provided.

The output hosted feature service is stored and shared on the hosting server.

Syntax: A JSON object describes the output feature service.

Example:

```javascript
//Portal Item ID
outputObjects={"itemId": <portal item id>}

//Hosted Feature Service URL
outputObjects={"url": <hosted feature service url>}

//Feature Class Local Output Path
outputObjects={"uri": <feature class local output path>}

//Service Properties
outputObjects={"serviceProperties":{"name":"testrasteranalysis","serviceUrl":"https://<server name>/server/rest/services/Hosted/testrasteranalysis/FeatureServer"},"itemProperties":{"itemId":"8cfbd3ec25584d0d8fed23b8ff7c43b", "folderId":"sdfwerfbd3ec25584d0d8f4"}}

```

 

</StyledTableCell>
</StyledTableRow>
<StyledTableRow>
<StyledTableCell cellStyle="markdown">

`model` 

(Required)

</StyledTableCell>
<StyledTableCell cellStyle="markdown">

The deep learning model to use to detect objects. This can be specified as the deep learning model portal item IS, an `.emd`  or `.dlpk`  file, or the entire JSON string of the model definition.

Syntax: A JSON object describes the model.

Example:

```javascript
//Portal Item
model={"itemId": "x2u130909jcvojzkeeraedf"}
model={"url": "https://<portal name>/portal/sharing/rest/content/items/x2u130909jcvojzkeeraedf"}

//.emd or .dlpk file
model={"uri": "\\\\sharedstorage\\sharefolder\\DetectTrees.emd"}
model={"uri": "\\\\sharedstorage\\sharefolder\\DetectTrees.dlpk"}
model={"uri": "/rasterStores/rasterstorename/A/B/DetectTrees.emd"}
model={"uri": "/rasterStores/rasterstorename/A/B/DetectTrees.dlpk"}

//.emd or .dlpk file stored in raster store with file share type
model = {"uri": "/fileShares/filesharedatastorename/A/B/ClassifyHouseDamage.emd"}
model={"uri": "/fileShares/filesharedatastorename/A/B/model.dlpk"}

```

 

JSON object example

```javascript
model={"Framework":"TensorFlow","ModelConfiguration":"ObjectDetectionAPI","ModelFile":"frozen_inference_graph.pb","ModelType":"ObjectDetection","ImageHeight":850,"ImageWidth":850,"ExtractBands":[0,1,2],"Classes":[{"Value": 0,"Name":"Tree","Color":[0,255,0]}]}
```

 

</StyledTableCell>
</StyledTableRow>
<StyledTableRow>
<StyledTableCell cellStyle="markdown">

`modelArguments` 

</StyledTableCell>
<StyledTableCell cellStyle="markdown">

The name value pairs of arguments and their values that can be customized by the clients.

Syntax: A JSON object describes the value pairs of arguments.

Example:

```javascript
modelArguments={"name1":"value1","name2": "value2"}
```

 

</StyledTableCell>
</StyledTableRow>
<StyledTableRow>
<StyledTableCell cellStyle="markdown">

`runNMS` 

</StyledTableCell>
<StyledTableCell cellStyle="markdown">

Specifies whether to perform nonmaximum suppression in which duplicate detected objects are identified and the duplicate with a lower confidence value is removed. When this parameter is set to `true` , duplicate objects with lower confidence scores will be removed. When it's set to `false` , all objects that are detected will be included in the output feature class. The default is `false` .

Values: `true`  \| `false` 

</StyledTableCell>
</StyledTableRow>
<StyledTableRow>
<StyledTableCell cellStyle="markdown">

`confidenceScoreField` 

</StyledTableCell>
<StyledTableCell cellStyle="markdown">

The name of the field in the feature service that contains the confidence scores as output by the object detection method. This parameter is required when `runNMS`  is set to `true` .

Example

```javascript
confidenceScoreField="Confidence"
```

 

</StyledTableCell>
</StyledTableRow>
<StyledTableRow>
<StyledTableCell cellStyle="markdown">

`classValueField` 

</StyledTableCell>
<StyledTableCell cellStyle="markdown">

The name of the class value field in the output feature service. If no value is specified, the tool will use the standard class value fields `Classvalue`  and `Value` . If these fields do not exist, all features will be treated as the same object class.

Example

```javascript
classValueField="Classvalue"
```

 

</StyledTableCell>
</StyledTableRow>
<StyledTableRow>
<StyledTableCell cellStyle="markdown">

`maxOverlapRatio` 

</StyledTableCell>
<StyledTableCell cellStyle="markdown">

The maximum overlap ratio for two overlapping objects, which is defined as the ratio of intersection area over union area. The default is 0.

Example

```javascript
maxOverlapRatio=0.3
```

 

</StyledTableCell>
</StyledTableRow>
<StyledTableRow>
<StyledTableCell cellStyle="markdown">

`processAllRasterItems` 

</StyledTableCell>
<StyledTableCell cellStyle="markdown">

Specifies how raster items in an image service will be processed. When this parameter is set to `true` , all raster items in the image service will be processed as separate images. When it's set to `false` , all raster items in the image service will be mosaicked together and processed. The default is `false` .

Values: `true`  \| `false` 

</StyledTableCell>
</StyledTableRow>
<StyledTableRow>
<StyledTableCell cellStyle="markdown">

`context` 

</StyledTableCell>
<StyledTableCell cellStyle="markdown">

Contains additional settings that affect task execution. This task has the following settings:

-   <GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_LI_2DDA48A24C404781BB03BF05B81B3C19 />
-   <GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_LI_1744B5CA044F44D8ABF2E27EF9BC9A27 />
-   <GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_LI_30623A2523584FB586A882C09EA092E6 />
-   <GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_LI_CE9516B4F2CC486AB1D7309DCF46BB60 />
-   <GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_LI_E5BF6567427444E8B74C6B8212C56B99 />
-   <GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_LI_E6010ACCD39749768E03E99ED0668169 />
-   <GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_LI_6DD48DC1AA3045459CB9C0154F7E1928 />

</StyledTableCell>
</StyledTableRow>
<StyledTableRow>
<StyledTableCell cellStyle="markdown">

`f` 

</StyledTableCell>
<StyledTableCell cellStyle="markdown">

<GUID_187EFF3C_6544_4421_8D1E_9DFCF76354CD_GUID_56FBFBA3_C66E_404D_8D62_38D68537B266 />

Values: `html`  \| `json`  \| `pjson` 

</StyledTableCell>
</StyledTableRow>
</StyledTable>

## Example usage

The following is a sample request URL for `DetectObjectsUsingDeepLearning` :

```javascript
https://machine.domain.com/webadaptor/rest/services/System/RasterAnalysisTools/GPServer/DetectObjectsUsingDeepLearning?
inputRaster="url":"https://<server name>/arcgis/ArcGIS/rest/services/World_Imagery/MapServer"&outputFeatureClass={"serviceProperties":{"name":"DetectedTrees"}}&model={"itemId": "d8d3902b41854529a907ad9f42af5a06"}&modelArguments={"padding": "0", "batch_size": "16"}&classLabelField=ClassLabel&processAllRasterItems=false&context={"extent": {"xmin": -13160539.4563053,"ymin": 3998752.62631951,"xmax": -13160427.5538234,"ymax": 3998824.51069532,"spatialReference": {"wkid": 3857}},"processorType": "CPU","parallelProcessingFactor": 2}}&f=json
```

 

## Response

<GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_GUID_1702083F_151C_4A0C_AF36_0D0DD9E2563A />

<GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_GUID_4B398B66_01FD_40FB_9AEE_30371F0A8CD8 />

<GUID_92B97D46_70DD_4B77_80C3_E6A319680CD9_GUID_ED11CCC7_40D3_4ADD_A679_A3F6964834ED />

```javascript
https://<raster analysis tools url>/DetectObjectsUsingDeepLearning/jobs/<jobId>
```

 

<GUID_187EFF3C_6544_4421_8D1E_9DFCF76354CD_GUID_D4B95D4E_8EB2_4216_A791_F294FC055A0B />

```javascript
https://<raster analysis tools url>/DetectObjectsUsingDeepLearning/jobs/<jobId>/results/outObjects
```

 

## JSON Response example

The response returns the `outObjects`  output parameter, which has properties for parameter name, data type, and value. The content of the value is always the output feature layer itemId and the image service URL.

```javascript
{
  "paramName": "outObjects",
  "dataType": "GPFeatureRecordSetLayer",
  "value": {
    "itemId": "f121390b85ef419790479fc75b493efd",
    "url": "https://<server name>/arcgis/rest/services/Hosted/<service name>/ImageServer"
  }
}
```

 
